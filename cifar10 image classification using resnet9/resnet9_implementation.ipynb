{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gpjfs5eR2PKz"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import os\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision.utils import make_grid\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import random_split\n",
        "import torchvision.transforms as tt\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "matplotlib.rcParams['figure.facecolor'] = '#ffffff'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1- Data normalization\n",
        "\n",
        "2- Data Augmentation\n",
        "\n",
        "3- Residual clipping \n",
        "\n",
        "4- Batch normalization\n",
        "\n",
        "5- Learning Rate Shceduling \n",
        "\n",
        "6- weight Decay\n",
        "\n",
        "7- Gradient clipping \n",
        "\n",
        "8- Adam optimizer"
      ],
      "metadata": {
        "id": "ujybJrw-2SoW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = '/content/drive/MyDrive/Colab Notebooks/cifar10'\n",
        "print(os.listdir(data_dir))\n",
        "classes = os.listdir(data_dir+'/train')\n",
        "print(classes)"
      ],
      "metadata": {
        "id": "HuouQrG_2QHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can create training and validation datasets using the ImageFolder class from torchvision. In addition to the ToTensor transform, we'll also apply some other transforms to the images. There are a few important changes we'll make while creating pytorch datasets for training and validation.\n",
        "\n",
        "1- Use test set for validation - Instead of setting aside a fraction of the data from the training set for validation, we'll simply use the test as our validation set. This just gives a little more data to train with. In general, once you have picked the best model architecture and hyperparameters using a fixed validation set, it is good idea to retrain the same model on the entire dataset just to give it a small final boost performance.\n",
        "\n",
        "2- channel-wise data normalization - We will normalize the image tensors by subracting the mean and dividing by the standard deviation across each channel. As a result, the mean of the data across each channel is 0, and standard deviation 1. Normalizing the data prevents the values from any one channel from disproportionately affecting the losses and gradients while training, simply by having a higher or wider range of values that others.\n",
        "\n",
        "3- Randomized data augmentation - We will apply random chosen transformation while loading images from the training dataset. Specifically, we will pad each image by 4 pixels, and then take a random crop of size 32x32 pixels, and then flip the image horizontally with a 50% probability. Since the transformation will be applied randomly and dynamically each time a particular image is loaded, the model sees slightly different images in each epoch of training, which allows it generalize better."
      ],
      "metadata": {
        "id": "nZPslf0l2YSI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# stats - mean and standard deviation across all images across all pixels\n",
        "stats = ((0.4914,0.4822,0.4465),(0.2023,0.1994,0.2010))\n",
        "train_transformations = tt.Compose([tt.RandomCrop(32,padding=4,padding_mode='reflect'),\n",
        "                              tt.RandomHorizontalFlip(),\n",
        "                              tt.RandomRotation(10),\n",
        "                              tt.RandomResizedCrop(256,scale=(0.5,0.9),ratio=(1,1)),\n",
        "                              tt.ColorJitter(brightness=0.1,contrast=0.1,saturation=0.1),\n",
        "                              tt.ToTensor(),\n",
        "                              tt.Normalize(*stats,inplace=True)\n",
        "                              ])\n",
        "valid_transformations = tt.Compose([tt.ToTensor(),tt.Normalize(*stats)])   # cannot transform in validation set"
      ],
      "metadata": {
        "id": "2RAifOv52W7A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pytorch datasets\n",
        "train_ds = ImageFolder(data_dir+'/train',train_transformations)\n",
        "valid_ds = ImageFolder(data_dir+'/test',valid_transformations)"
      ],
      "metadata": {
        "id": "5rFF0bpe2mMj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can create data loaders for retrieving images in batches. "
      ],
      "metadata": {
        "id": "5CcSKvAH2qkG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=64\n",
        "# data laoders\n",
        "train_dl = DataLoader(train_ds,batch_size,shuffle=True,num_workers=3,pin_memory=True)\n",
        "valid_dl = DataLoader(valid_ds,batch_size*2,num_workers=3,pin_memory=True)"
      ],
      "metadata": {
        "id": "jNYXQ4fl2vu9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To display the images, we'll need to denormalize the pixels values to bring them back into the range(0,1)"
      ],
      "metadata": {
        "id": "OdiexNW820cE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def denormalize(images,means,stds):             # undoing the normalization\n",
        "  means = torch.tensor(means).reshape(1,3,1,1)\n",
        "  stds = torch.tensor(stds).reshape(1,3,1,1)\n",
        "  return images*stds + means\n",
        "\n",
        "def show_batch(dl):\n",
        "  for images,labels in dl:\n",
        "    fig,ax = plt.subplots(figsize=(12,12))\n",
        "    ax.set_xticks([]); ax.set_yticks([])\n",
        "    denorm_images = denormalize(images,*stats)\n",
        "    ax.imshow(make_grid(denorm_images[:64],nrow=8).permute(1,2,0).clamp(0,1))\n",
        "    break"
      ],
      "metadata": {
        "id": "nJJPmD3J21If"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_batch(train_dl)"
      ],
      "metadata": {
        "id": "sCw-DYaV24om"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_default_device():\n",
        "  \"\"\"Pick GPU if available else CPU\"\"\"\n",
        "  if torch.cuda.is_available():\n",
        "    return torch.device('cuda')\n",
        "  else:\n",
        "    return torch.device('cpu')\n",
        "\n",
        "def to_device(data,device):\n",
        "  \"\"\"move tensor to the choosen device\"\"\"\n",
        "  if isinstance(data,(list,tuple)):\n",
        "    return [to_device(x,device) for x in data]\n",
        "  return data.to(device,non_blocking=True)\n",
        "\n",
        "class DeviceDataLoader():\n",
        "  \"\"\"wrap a dataloader to move data to a device\"\"\"\n",
        "  def __init__(self,dl,device):\n",
        "    self.dl = dl\n",
        "    self.device = device\n",
        "\n",
        "  def __iter__(self):\n",
        "    \"\"\"Yeild a batch of data after moving it to device\"\"\"\n",
        "    for b in self.dl:\n",
        "      yield to_device(b,self.device)              # yield keyword in python is used to create a generator function that can be used within  a for loop\n",
        "  \n",
        "  def __len__(self):\n",
        "    \"\"\"Number of batches\"\"\"\n",
        "    return len(self.dl)\n",
        "\n",
        "device = get_default_device()\n",
        "print(device)\n",
        "# we can now wrap our data loaders using DeviceDataLoader\n",
        "train_dl = DeviceDataLoader(train_dl,device)\n",
        "val_dl = DeviceDataLoader(valid_dl,device) \n",
        "# Shifting model on GPU"
      ],
      "metadata": {
        "id": "kI0kVHLR28Y5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model with residual blocks and batch normalization\n",
        "\n",
        "**While training ResNets, we either train the layers in residual blocks or skip the training for those layers using skip connections. So, different parts of networks will be trained at different rates for different training data points based on how the error flows backward in the network. This can be thought of as training an ensemble of different models on the dataset and getting the best possible accuracy.**\n",
        "\n",
        "**Skipping training in some residual block layers can be looked at from an optimistic point of view too. In general, we do not know the optimal number of layers (or residual blocks) required for a neural network which might depend on the complexity of the dataset. Instead of treating the number of layers as an important hyperparameter to tune, by adding skip connections to our network, we are allowing the network to skip training for the layers that are not useful and do not add value in overall accuracy. In a way, skip connections make our neural networks dynamic to tune the number of layers during training optimally.**"
      ],
      "metadata": {
        "id": "BGDn9UCa2_9z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In residual blocks we cannot change the number of ouput channel because we have to match output and input i.e g(out + x) to make it compatible for the tensor operation"
      ],
      "metadata": {
        "id": "VO5syqyc3FQ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleResidualBlock(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=3,out_channels=3,kernel_size=3,stride=1,padding=1)\n",
        "    self.relu1 = nn.ReLU()\n",
        "    self.conv2 = nn.Conv2d(in_channels=3,out_channels=3,kernel_size=3,stride=1,padding=1)\n",
        "    self.relu2 = nn.ReLU()\n",
        "\n",
        "  def forward(self,x):    # x - (400,3,32,32)\n",
        "    out = self.conv1(x)    # (400,3,32,32)\n",
        "    out = self.relu1(out)   # (400,3,32,32)\n",
        "    out = self.conv2(out)   # (400,3,32,32)\n",
        "    out = self.relu2(out+x)   # (400,3,32,32) + (400,3,32,32)\n",
        "    return out"
      ],
      "metadata": {
        "id": "bNC_KYc_3A8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "simple_resnet = to_device(SimpleResidualBlock(),device)\n",
        "for images,label in train_dl:\n",
        "  print('input shape:',images.shape)\n",
        "  out = simple_resnet(images)\n",
        "  print('output shape:',out.shape)\n",
        "  break"
      ],
      "metadata": {
        "id": "Xnag-FWO3Jbv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This seemingly small change produces a drastic improvement in the performance of the model. Also, after convolution layer, we'll add a **batch normalization layer**, which normalizes the outputs of the previous layer.\n",
        "\n",
        "batch normalization layer normalizes the output of the previous layer so that all the channels have the similar distribution."
      ],
      "metadata": {
        "id": "Mym6hfRz3Mdo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resnet9 "
      ],
      "metadata": {
        "id": "stKz14BP3Ozn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(outputs,labels):\n",
        "  _,preds = torch.max(outputs,dim=1)\n",
        "  return torch.tensor(torch.sum(preds == labels).item()/len(preds))\n",
        "\n",
        "class ImageClassificationBase(nn.Module):\n",
        "  def training_step(self,batch):\n",
        "    images,labels = batch\n",
        "    out = self(images)\n",
        "    loss = F.cross_entropy(out,labels)\n",
        "    return loss\n",
        "  \n",
        "  def validation_step(self,batch):\n",
        "    images,labels = batch\n",
        "    out = self(images)\n",
        "    loss = F.cross_entropy(out,labels)\n",
        "    acc = accuracy(out,labels)\n",
        "    return {'val_loss':loss.detach(),'val_acc':acc}\n",
        "  \n",
        "  def validation_epoch_end(self,outputs):\n",
        "    batch_losses = [x['val_loss'] for x in outputs]\n",
        "    epoch_loss = torch.stack(batch_losses).mean()\n",
        "    batch_accs = [x['val_acc'] for x in outputs]\n",
        "    epoch_acc = torch.stack(batch_accs).mean()\n",
        "    return {'val_loss':epoch_loss.item(),'val_acc':epoch_acc.item()}\n",
        "  \n",
        "  def epoch_end(self,epoch,result):\n",
        "    print(\"Epoch [{}] ,val_loss : {:.4f}, val_acc : {:.4f}\".format(epoch,result['val_loss'],result['val_acc']))\n",
        "\n",
        "\n",
        "def conv_block(in_channels,out_channels,pool=False):           \n",
        "  layers = [nn.Conv2d(in_channels,out_channels,kernel_size=3,padding=1),      # layer containing conv, batch_normalization, activation fn and pooling layer if true \n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)]\n",
        "  if pool : layers.append(nn.MaxPool2d(2))\n",
        "  return nn.Sequential(*layers)\n",
        "\n",
        "class ResNet9(ImageClassificationBase):\n",
        "  def __init__(self,in_channels,num_classes):\n",
        "    super().__init__()                              # input - 3,256,256\n",
        "    self.conv1 = conv_block(in_channels,64)         # out1 - \n",
        "    self.conv2 = conv_block(64,128,pool=True)\n",
        "    self.res1 = nn.Sequential(conv_block(128,128),conv_block(128,128))     # residual layers having same inputs as outputs\n",
        "    \n",
        "    self.conv3 = conv_block(128,256,pool=True)\n",
        "    self.conv4 = conv_block(256,512,pool=True)\n",
        "    self.res2 = nn.Sequential(conv_block(512,512),conv_block(512,512))  # residual layers having same inputs as outputs\n",
        "    \n",
        "    self.classifier = nn.Sequential(nn.MaxPool2d(4),     #Dense Network   \n",
        "                                    nn.Flatten(),\n",
        "                                    nn.Dropout(0.2),\n",
        "                                    nn.Linear(512,num_classes))\n",
        "  def forward(self,xb):\n",
        "    out = self.conv1(xb)\n",
        "    #print('conv1 output:', out.shape)\n",
        "    out = self.conv2(out)\n",
        "    #print('conv2 output:', out.shape)\n",
        "    out = self.res1(out) + out\n",
        "    #print('res1 output:',out.shape)\n",
        "    out = self.conv3(out)\n",
        "    #print('conv3 output:',out.shape)\n",
        "    out = self.conv4(out)\n",
        "    #print('conv4 output:',out.shape)\n",
        "    out = self.res2(out) + out \n",
        "    #print('res2 output:',out.shape)\n",
        "    out = self.classifier(out)\n",
        "    return out\n",
        "  "
      ],
      "metadata": {
        "id": "-iZHcihi3Pj6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = to_device(ResNet9(3,10),device)\n",
        "model"
      ],
      "metadata": {
        "id": "wf1lfymE3TRs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the model -\n",
        "\n",
        "improvements in training -\n",
        "\n",
        "1- **Learning rate Scheduling** - Instead of using fixed learning rate, we will use a learning rate scheduler, which will change the learning after every batch of training. \n",
        " https://sgugger.github.io/the-1cycle-policy.html\n",
        "\n",
        "There are many strategies for varying the learning rate during training, and the one we'll use is called the \"**One Cycle Learning Rate Policy**\", which involves starting with a low learning rate, gradually increasing it batch-by-batch to a high learning rate for about 30% of epochs, then gradually decreasing it to very low value for the remaining epochs.\n",
        "\n",
        "2- **Weight Decay** - We also use weight decay, which is yet another regularization technique which prevents the weights from becoming too large by adding an additional term to the loss function.\n",
        " https://towardsdatascience.com/this-thing-called-weight-decay-a7cd4bcfccab\n",
        "\n",
        "3- **Gradient Clipping** - limiting the values of the gradients to a small range to prevent undesirable changes in parameters due to large gradients."
      ],
      "metadata": {
        "id": "JjVkzciX3Wc3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining fit one cycle function to incorporate these changes"
      ],
      "metadata": {
        "id": "8JmV_Z4d3Y3P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model,val_loader):\n",
        "  model.eval()\n",
        "  outputs = [model.validation_step(batch) for batch in val_loader]\n",
        "  return model.validation_epoch_end(outputs)\n",
        "\n",
        "def get_lr(optimizer):\n",
        "  for param_group in optimizer.para_groups:\n",
        "    return param_group['lr']\n",
        "\n",
        "\n",
        "def fit_one_cycle(epochs,max_lr,model,train_loader,val_loader,weight_decay=0,grad_clip=None,opt_func=torch.optim.SGD):\n",
        "  torch.cuda.empty_cache()\n",
        "  history=[]\n",
        "  # set up custom optimizer with weight decay\n",
        "  optimizer = opt_func(model.parameters(),max_lr,weight_decay=weight_decay)\n",
        "  # set up one cycle learning rate scheduler\n",
        "  sched = torch.optim.lr_scheduler.OneCycleLR(optimizer,max_lr,epochs=epochs,steps_per_epoch=len(train_loader))\n",
        "  \n",
        "  for epoch in range(epochs):\n",
        "    # training_phase\n",
        "    model.train()\n",
        "    train_losses=[]\n",
        "    lrs=[]\n",
        "    for batch in train_loader:\n",
        "      loss = model.training_step(batch)\n",
        "      train_losses.append(loss)\n",
        "      loss.backward()\n",
        "\n",
        "      # gradient clipping\n",
        "      if grad_clip:\n",
        "        nn.utils.clip_grad_value(model.parameters(),grad_clip)\n",
        "      \n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # record and update learning rate\n",
        "      lrs.append(get_lr(optimizer))\n",
        "      sched.step()\n",
        "\n",
        "    #validation step\n",
        "    result = evaluate(model,val_loader)\n",
        "    result['train_loss'] = torch.stack(train_losses).mean().item()\n",
        "    result['lrs'] = lrs \n",
        "    model.epoch_end()\n",
        "    history.append(result)\n",
        "  return history"
      ],
      "metadata": {
        "id": "nyKDhVFI3bH8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = [evaluate(model,val_dl)]\n",
        "history"
      ],
      "metadata": {
        "id": "fMNWbuJx3c-f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "epochs = 8\n",
        "max_lr = 0.01\n",
        "grad_clip = 0.1\n",
        "weight_decay = 1e-4\n",
        "opt_func = torch.optim.Adam     # Adam optimizer"
      ],
      "metadata": {
        "id": "siWHCND_3e-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history+=[fit_one_cycle(epochs,max_lr,model,train_dl,valid_dl,grad_clip=grad_clip,weight_decay=weight_decay,opt_func=opt_func)]"
      ],
      "metadata": {
        "id": "WHEv0KAq3gpn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_accuracies(history):\n",
        "    accuracies = [x['val_acc'] for x in history]\n",
        "    plt.plot(accuracies, '-x')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.title('Accuracy vs. No. of epochs');\n",
        "\n",
        "plot_accuracies(history)"
      ],
      "metadata": {
        "id": "aNnkkrcR3icw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_lrs(history):\n",
        "    lrs = np.concatenate([x.get('lrs', []) for x in history])\n",
        "    plt.plot(lrs)\n",
        "    plt.xlabel('Batch no.')\n",
        "    plt.ylabel('Learning rate')\n",
        "    plt.title('Learning Rate vs. Batch no.');\n",
        "\n",
        "plot_lrs(history)"
      ],
      "metadata": {
        "id": "2F0sODE63kS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing with individual images"
      ],
      "metadata": {
        "id": "0FLQtnx-3mTm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_image(img, model):\n",
        "    # Convert to a batch of 1\n",
        "    xb = to_device(img.unsqueeze(0), device)\n",
        "    # Get predictions from model\n",
        "    yb = model(xb)\n",
        "    # Pick index with highest probability\n",
        "    _, preds  = torch.max(yb, dim=1)\n",
        "    # Retrieve the class label\n",
        "    return train_ds.classes[preds[0].item()]\n",
        "\n"
      ],
      "metadata": {
        "id": "_uUCDBDa3oHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img, label = valid_ds[0]\n",
        "plt.imshow(img.permute(1, 2, 0).clamp(0, 1))\n",
        "print('Label:', train_ds.classes[label], ', Predicted:', predict_image(img, model))"
      ],
      "metadata": {
        "id": "U5Fq5ZR-3qkZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img, label = valid_ds[1002]\n",
        "plt.imshow(img.permute(1, 2, 0))\n",
        "print('Label:', valid_ds.classes[label], ', Predicted:', predict_image(img, model))"
      ],
      "metadata": {
        "id": "SuCZTA7L3sWR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}